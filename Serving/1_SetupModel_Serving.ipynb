{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setting Up Chameleon Environment for Serving\n",
        "- site being used here is\n",
        "- Model Serving in"
      ],
      "metadata": {
        "id": "-MKOEwWrLwFF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A77y74RhLiC4"
      },
      "outputs": [],
      "source": [
        "from chi import server, context, lease\n",
        "import os\n",
        "\n",
        "context.version = \"1.0\"\n",
        "context.choose_project()\n",
        "context.choose_site(default=\"CHI@TACC\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = lease.get_lease(f\"serve_model_netID\")\n",
        "l.show()"
      ],
      "metadata": {
        "id": "E7pPqbwcLw88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "username = os.getenv('USER') # all exp resources will have this prefix\n",
        "s = server.Server(\n",
        "    f\"node-serve-model-{username}\",\n",
        "    reservation_id=l.node_reservations[0][\"id\"],\n",
        "    image_name=\"CC-Ubuntu24.04-CUDA\"\n",
        ")\n",
        "s.submit(idempotent=True)"
      ],
      "metadata": {
        "id": "1DPcstcQLxEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s.associate_floating_ip()"
      ],
      "metadata": {
        "id": "GEjAaja1dQoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s.refresh()\n",
        "s.check_connectivity()"
      ],
      "metadata": {
        "id": "J8y9FSRfdSZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s.refresh()\n",
        "s.show(type=\"widget\")"
      ],
      "metadata": {
        "id": "gus1uQExdS8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Git Clone LLM Summarization\n",
        "\n"
      ],
      "metadata": {
        "id": "h24a15nbLxhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s.execute(\"https://github.com/shettynitis/LLM_LegalDocSummarization.git\")"
      ],
      "metadata": {
        "id": "baNMl57Fdk-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting Up Docker"
      ],
      "metadata": {
        "id": "iPq7hynTLyBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s.execute(\"curl -sSL https://get.docker.com/ | sudo sh\")\n",
        "s.execute(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")"
      ],
      "metadata": {
        "id": "FNk9Xwe_eHgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the NVIDIA container toolkit"
      ],
      "metadata": {
        "id": "6ppd4XcoeSPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s.execute(\"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
        "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n",
        "    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
        "    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\")\n",
        "s.execute(\"sudo apt update\")\n",
        "s.execute(\"sudo apt-get install -y nvidia-container-toolkit\")\n",
        "s.execute(\"sudo nvidia-ctk runtime configure --runtime=docker\")\n",
        "# for https://github.com/NVIDIA/nvidia-container-toolkit/issues/48\n",
        "s.execute(\"sudo jq 'if has(\\\"exec-opts\\\") then . else . + {\\\"exec-opts\\\": [\\\"native.cgroupdriver=cgroupfs\\\"]} end' /etc/docker/daemon.json | sudo tee /etc/docker/daemon.json.tmp > /dev/null && sudo mv /etc/docker/daemon.json.tmp /etc/docker/daemon.json\")\n",
        "s.execute(\"sudo systemctl restart docker\")"
      ],
      "metadata": {
        "id": "DoMkfyQVeM2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Open an SSH session\n",
        "\n",
        "Finally, open an SSH sesson on your server. From your local terminal, run\n",
        "\n",
        "``ssh -i ~/.ssh/id_rsa_chameleon cc@A.B.C.D``\n",
        "\n",
        "where,\n",
        "\n",
        "in place of ~/.ssh/id_rsa_chameleon, substitute the path to our project key that you had uploaded\n",
        "\n",
        "in place of A.B.C.D, use the floating IP address you just associated to your instance."
      ],
      "metadata": {
        "id": "a3TZE8wqedyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare data\n",
        "\n",
        "- Create a volume\n",
        "````\n",
        "# runs on node\n",
        "docker volume create llm-data\n",
        "````\n",
        "\n",
        "- Populate it with data\n",
        "````\n",
        "# runs on node\n",
        "docker compose -f serve-model-chi/docker/docker-compose-data.yaml up -d\n",
        "````\n",
        "\n",
        "- To check if the container is still running\n",
        "````\n",
        "# runs on node-serve-model\n",
        "docker ps\n",
        "````\n",
        "- Start a shell in a temporary container with this volume attached\n",
        "````\n",
        "# run on nodeâ€‘mltrain (or whatever node you leased)\n",
        "docker run --rm -it -v llm-data:/mnt alpine ls -l /mnt/merged_dataset/\n",
        "````"
      ],
      "metadata": {
        "id": "iWbWfVPkmJRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Launch a Jupyter container\n",
        "\n",
        "````\n",
        "# run on node server\n",
        "docker build -t jupyter-onnx -f LLM_LegalDocSummarization/docker/Dockerfile.jupyter-onnx-gpu .\n",
        "\n",
        "````\n",
        "\n",
        "\n",
        "````\n",
        "# run on node server\n",
        "docker run  -d --rm  -p 8888:8888 \\\n",
        "    --gpus all \\\n",
        "    --shm-size 16G \\\n",
        "    -v ~/LLM_LegalDocSummarization:/home/jovyan/work \\\n",
        "    -v llm-data:/mnt/ \\\n",
        "    -e LLM_DATA_DIR=/mnt/merged_dataset \\\n",
        "    --name jupyter \\\n",
        "    jupyter-onnx\n",
        "\n",
        "````\n",
        "\n",
        "````\n",
        "# run on node server\n",
        "docker logs jupyter\n",
        "````\n",
        "\n",
        "and look for a line like\n",
        "````\n",
        "http://127.0.0.1:8888/lab?token=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
        "````"
      ],
      "metadata": {
        "id": "lqv24bxUiSci"
      }
    }
  ]
}