{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Ray cluster - NVIDIA GPUs\n",
    "\n",
    "> **Note**: Follow these instructions only if you are running this experiment on a node with NVIDIA GPUs.\n",
    "\n",
    "For the Ray experiment, you must use a node with two GPUs. Run\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "nvidia-smi\n",
    "```\n",
    "\n",
    "and confirm that you see two GPUs.\n",
    "\n",
    "We’ll bring up our Ray cluster with Docker Compose. Run:\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "export HOST_IP=$(curl --silent http://169.254.169.254/latest/meta-data/public-ipv4 )\n",
    "docker compose -f LLM_LegalDocSummarization/docker/docker-compose-ray-cuda.yaml up -d\n",
    "```\n",
    "\n",
    "You can see this Docker Compose YAML here: [docker-compose-ray-cuda.yaml](https://github.com/teaching-on-testbeds/mltrain-chi/blob/main/docker/docker-compose-ray-cuda.yaml).\n",
    "\n",
    "When it is finished, the output of\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "docker ps\n",
    "```\n",
    "\n",
    "should show that the `ray-head`, `ray-worker-0`, and `ray-worker-1` containers are running.\n",
    "\n",
    "Although the host has 2 GPUs, we only passed one to each worker. Run\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "docker exec -it ray-worker-0 nvidia-smi --list-gpus\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "docker exec -it ray-worker-1 nvidia-smi --list-gpus\n",
    "```\n",
    "\n",
    "and confirm that only one GPU appears in the output, and it is a different GPU (different UUID) in each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a Jupyter container\n",
    "\n",
    "Next, let’s start a Jupyter notebook container that does *not* have any GPUs attached. We’ll use this container to submit jobs to the Ray cluster.\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "docker build -t jupyter-ray -f LLM_LegalDocSummarization/docker/Dockerfile.jupyter-ray .\n",
    "```\n",
    "\n",
    "Run\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "HOST_IP=$(curl --silent http://169.254.169.254/latest/meta-data/public-ipv4 )\n",
    "docker run  -d --rm  -p 8888:8888 \\\n",
    "    -v ~/LLM_LegalDocSummarization:/home/jovyan/work/ \\\n",
    "    -e RAY_ADDRESS=http://${HOST_IP}:8265/ \\\n",
    "    -e MERGED_DATA_DIR=/mnt/LLMData \\\n",
    "    --mount type=bind,source=/mnt/LLMData,target=/mnt/LLMData,readonly \\\n",
    "    --name jupyter \\\n",
    "    jupyter-ray\n",
    "```\n",
    "\n",
    "Then, run\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "docker logs jupyter\n",
    "```\n",
    "\n",
    "and look for a line like\n",
    "\n",
    "    http://127.0.0.1:8888/lab?token=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "Paste this into a browser tab, but in place of `127.0.0.1`, substitute the floating IP assigned to your instance, to open the Jupyter notebook interface.\n",
    "\n",
    "In the file browser on the left side, open the `work` directory.\n",
    "\n",
    "Open a terminal (“File \\> New \\> Terminal”) inside the Jupyter server environment, and in this terminal, run\n",
    "\n",
    "``` bash\n",
    "# runs on jupyter container inside node-mltrain\n",
    "env\n",
    "```\n",
    "\n",
    "to see environment variables. Confirm that the `RAY_ADDRESS` is set, with the correct floating IP address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Ray cluster dashboard\n",
    "\n",
    "The Ray head node serves a dashboard on port 8265. In a browser, open\n",
    "\n",
    "    http://A.B.C.D:8265\n",
    "\n",
    "where in place of `A.B.C.D`, substitute the floating IP associated with your server.\n",
    "\n",
    "Click on the “Cluster” tab and verify that you see your head node and two worker nodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
